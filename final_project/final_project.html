<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-06-09">

<title>Los Angeles Crime Analysis - Predicting the Sex of Victims</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="final_project_files/libs/clipboard/clipboard.min.js"></script>
<script src="final_project_files/libs/quarto-html/quarto.js"></script>
<script src="final_project_files/libs/quarto-html/popper.min.js"></script>
<script src="final_project_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="final_project_files/libs/quarto-html/anchor.min.js"></script>
<link href="final_project_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="final_project_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="final_project_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="final_project_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="final_project_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Los Angeles Crime Analysis - Predicting the Sex of Victims</h1>
            <p class="subtitle lead">Camden Possinger, Sehee Han, Bradley Parmer-Lohan</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 9, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="final_project.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>Certain crimes frequently target specific groups based on race, gender, nationality, age, and religion. This phenomenon could lead to the increase of hate crime, create conflicts among the society and generate a huge amount of social costs accordingly. To develop the strategies for preventing targeting crimes, it is necessary for us to analyze and predict the characteristics of the victims. In particular, this report aims to focus on predicting the gender breakdown of crime victims by using different supervised machine learning algorithms with several computational optimization techniques. Logistic Regression, Support Vector Machine, and Neural Network (NN) were used to predict the sex of victims (0: Male, 1: Female) based on the several explanatory variables. Additionally, the optimization methods such as Matrix Decompositions, PCA and Gradient Descent were applied to each algorithm to optimize the computing efficiency of the algorithms that were implemented. In this paper we compare these methods and are able to predict the sex of a crime victim with a reasonable F1 Score.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>With our exploration, we set out to establish a method of modeling that could accurately predict the sex of the victim of a crime in Los Angeles. This question is important, as it could potentially help the city to better dedicate support resources where they’re needed most, understand which groups are more likely to be the victims of violent crimes, and explore the unique vulnerabilities and risks faced by different genders in the city. In order to do this, we made use of a dataset curated by the Los Angeles City Police Department themselves. This dataset collects data on the victim of the crime, the type of crime, where and when it took place, and much more. In this dataset, each row is a crime incident. There are 730,990 records in this dataset, dating all the way back to January, 2019. We identified three separate algorithms that we could use in order to perform our data predictions. These methods are the Linear Regression, Support Vector Machine, and the Neural Network. We will optimize the algorithms by using several methods, and eventually compare the efficacy of each method, along with their feasibilities of estimation.</p>
</section>
<section id="proposed-methods" class="level1">
<h1>Proposed Methods</h1>
<section id="logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h2>
<p>The logistic regression works by taking any number of binary or continuous variables, and using them to calculate the probability of the chosen indicator variable given the log-odds of the data. This can be an ideal method to use in this scenario due to the binary nature of our dataset, both in our input and output variables. This method will also come in handy due to its relative ease of handling large datasets. Due to our one-hot encoding from the data cleaning process, we have close to 500 columns to filter through, and more than 500,000 rows of data to parse. That’s a big matrix! Luckily, the logistic regression method has multiple different avenues of calculation. These include, but are not limited to, the LU, SVD, and QR methods of decomposition. Of these three methods, the one that tends to be the most efficient in solving large, sparse matrices is the QR decomposition. This method exploits the sparsity of the matrix when performing calculations, which leads to a more efficient and faster result than the LU or SVD methods.</p>
</section>
<section id="svm" class="level2">
<h2 class="anchored" data-anchor-id="svm">SVM</h2>
<p>The primary concept behind Support Vector Machine (SVM) is to identify an optimal hyperplane that can effectively separate different classes of data points in a feature space with multiple dimensions. The selection of the hyperplane is based on maximizing the margin, which represents the distance between the hyperplane and the closest data points from each class. SVM employs the kernel trick, which facilitates the transformation of input features into a feature space of higher dimensions. Therefore we expected, at our first attempts, that we could benefit from this model which could deal with high dimensional datasets and help us achieve effective outcomes. Also, Quadratic Programming, Principal Component Analysis (PCA), Incremental Principal Component Analysis (IPCA),and Gradient Descent were applied to maximize the efficiency of this algorithm.</p>
</section>
<section id="mlp-binary-classifier" class="level2">
<h2 class="anchored" data-anchor-id="mlp-binary-classifier">MLP Binary Classifier</h2>
<p>A Multi Layer Perceptron Binary Classifier is a relatively simple neural network that takes advantage of gradient descent and backpropagation to find optimal values for all weights that connect the hidden layers to the output layer. Even though this method usies a simple architecture the training process takes a lot of time to converge and requres good quality data to produce useful predictions. It’s also worth mentioning that inference is not possible with a MLP Binary Classifier and can only be used for prediction.</p>
</section>
</section>
<section id="data-prep" class="level1">
<h1>Data Prep</h1>
<p>Before we could perform any of our Data Analysis using our proposed methods, however, we had to clean the data. Our dataset had several categorical columns, which were not compatible with any of our proposed methods. Of the 29 columns in the dataset, we turned one into our response variable (the sex of the victim), mean normalized two others (time of crime and victim age), one hot encoded four more (area name, crime code, victim descent, and premise description), and dropped the rest. The dropped columns were mostly unnecessarily redundant for our purposes, or just unreadable without the proper key. For example, there was a column which contained the crime code (e.g., 311), and another column which was the translation of the crime code (e.g., grand theft auto). Another example of unnecessary data was all of the location data – this was not a part of any of our analysis that we performed, and as such, it was not necessary or even feasible to keep it in the dataset. By dropping these unnecessary columns, we were able to achieve much lower computational costs when running our models. We also had to ensure that we did not introduce bias into our model. This necessitated dropping about 40,000 records of male crime victims in order to properly balance the data between male and female. The dropped records were selected randomly. It is also important to note that the final, fully numericized dataset has a sprasity of 97%. This is due to the fact there are so many columns created by the one hot encoding that was performed.</p>
<section id="reading-in-datamodules" class="level3">
<h3 class="anchored" data-anchor-id="reading-in-datamodules">Reading in Data/Modules</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> lu</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> qr</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> svd</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'Crime_Data_from_2020_to_Present.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="victim-sex-distribution" class="level3">
<h3 class="anchored" data-anchor-id="victim-sex-distribution">Victim Sex Distribution</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lets get a sense of what our value distribution looks like for the dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>value_counts <span class="op">=</span> data[<span class="st">'Vict Sex'</span>].value_counts()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>value_counts.plot.bar()</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Victim Sex'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Count'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.tight_layout()</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>plt.show</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="final_project_files/figure-html/cell-3-output-2.png" width="619" height="428"></p>
</div>
</div>
</section>
<section id="victim-mf-sex-distribution" class="level3">
<h3 class="anchored" data-anchor-id="victim-mf-sex-distribution">Victim M/F Sex Distribution</h3>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We drop all rows that aren't Male or Female sex</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>m_f <span class="op">=</span> [<span class="st">'M'</span>, <span class="st">'F'</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data[<span class="st">'Vict Sex'</span>].isin(m_f)]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>value_counts <span class="op">=</span> data[<span class="st">'Vict Sex'</span>].value_counts()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>value_counts.plot.bar()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Count'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.tight_layout()</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>plt.show</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="final_project_files/figure-html/cell-4-output-2.png" width="619" height="428"></p>
</div>
</div>
</section>
<section id="victim-sex-after-resample" class="level3">
<h3 class="anchored" data-anchor-id="victim-sex-after-resample">Victim Sex After Resample</h3>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now, we're going to randomly order the data so that we can even out </span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the number of male to female</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>random <span class="op">=</span> data.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># randomly select all of the female records because why not</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>female <span class="op">=</span> random.loc[data[<span class="st">'Vict Sex'</span>] <span class="op">==</span> <span class="st">'F'</span>]</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># more importantly, randomly select male records, </span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># but only as many as we have of female records</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>male <span class="op">=</span> random.loc[data[<span class="st">'Vict Sex'</span>] <span class="op">==</span> <span class="st">'M'</span>].sample(n <span class="op">=</span> <span class="bu">len</span>(female.index), </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                                                  random_state <span class="op">=</span> <span class="dv">69</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># recombine both of our datasets</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.concat([male, female])</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># make a graph to make sure we're good</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>value_counts <span class="op">=</span> data[<span class="st">'Vict Sex'</span>].value_counts()</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>value_counts.plot.bar()</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Victim Sex'</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Count'</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.tight_layout()</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.show</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset is balanced!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>&lt;function matplotlib.pyplot.show(close=None, block=None)&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="final_project_files/figure-html/cell-5-output-2.png" width="619" height="428"></p>
</div>
</div>
</section>
<section id="clean-features" class="level3">
<h3 class="anchored" data-anchor-id="clean-features">Clean Features</h3>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make it binary, Male is 0, Female is 1</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'Vict Sex'</span>] <span class="op">=</span> data[<span class="st">'Vict Sex'</span>].<span class="bu">map</span>({<span class="st">'M'</span>: <span class="dv">0</span>, <span class="st">'F'</span>: <span class="dv">1</span>})</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Manually setting whether or not a crime is violent or not. we don't really care </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># about the exact crime,</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># whether or not it's violent is more important. we can save data this way</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>violent <span class="op">=</span> [<span class="st">'ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT'</span>, <span class="st">'BATTERY - SIMPLE ASSAULT'</span>, </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>           <span class="st">'CRIMINAL HOMICIDE'</span>, <span class="st">'INTIMATE PARTNER - SIMPLE ASSAULT'</span>, </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>           <span class="st">'THROWING OBJECT AT MOVING VEHICLE'</span>, <span class="st">'DISCHARGE FIREARMS/SHOTS FIRED'</span>, </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>           <span class="st">'CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT'</span>, </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>           <span class="st">'INTIMATE PARTNER - AGGRAVATED ASSAULT'</span>, </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>           <span class="st">'CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT'</span>, </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>           <span class="st">'ASSAULT WITH DEADLY WEAPON ON POLICE OFFICER'</span>, </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>           <span class="st">'SHOTS FIRED AT INHABITED DWELLING'</span>,</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>          <span class="st">'SHOTS FIRED AT MOVING VEHICLE, TRAIN OR AIRCRAFT'</span>, <span class="st">'KIDNAPPING - GRAND ATTEMPT'</span>, </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>           <span class="st">'BATTERY POLICE (SIMPLE)'</span>, <span class="st">'SEX,UNLAWFUL(INC MUTUAL CONSENT, PENETRATION W/ FRGN OBJ'</span>, </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>           <span class="st">'OTHER ASSAULT'</span>, <span class="st">'SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH'</span>, </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>           <span class="st">'BATTERY WITH SEXUAL CONTACT'</span>, <span class="st">'BATTERY ON A FIREFIGHTER'</span>, </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>           <span class="st">'SEXUAL PENETRATION W/FOREIGN OBJECT'</span>, <span class="st">'KIDNAPPING'</span>, <span class="st">'RAPE, FORCIBLE'</span>, </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>           <span class="st">'CRUELTY TO ANIMALS'</span>, <span class="st">'LYNCHING - ATTEMPTED'</span>, <span class="st">'LYNCHING'</span>,</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>           <span class="st">'LEWD/LASCIVIOUS ACTS WITH CHILD'</span>, <span class="st">'MANSLAUGHTER, NEGLIGENT'</span>, </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>           <span class="st">'RAPE, ATTEMPTED'</span>, <span class="st">'PIMPING'</span>, <span class="st">'HUMAN TRAFFICKING - COMMERCIAL SEX ACTS'</span>, </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>           <span class="st">'HUMAN TRAFFICKING - INVOLUNTARY SERVITUDE'</span>, </span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>           <span class="st">'BEASTIALITY, CRIME AGAINST NATURE SEXUAL ASSLT WITH ANIM'</span>]</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co"># violent is 1, non-violent is 0</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'violent_y_n'</span>] <span class="op">=</span> np.where(data[<span class="st">'Crm Cd Desc'</span>].isin(violent), <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop all unnecesary or unusable/unreadable columns</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>columns_to_drop <span class="op">=</span> [<span class="st">'DR_NO'</span>, <span class="st">'Date Rptd'</span>, <span class="st">'AREA'</span>, <span class="st">'Rpt Dist No'</span>, <span class="st">'Part 1-2'</span>, </span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'Crm Cd'</span>, <span class="st">'Mocodes'</span>, <span class="st">'Premis Cd'</span>, <span class="st">'Weapon Used Cd'</span>, </span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'Status'</span>, <span class="st">'Status Desc'</span>, <span class="st">'Crm Cd 1'</span>, <span class="st">'Crm Cd 2'</span>, <span class="st">'Crm Cd 3'</span>,</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'Crm Cd 4'</span>, <span class="st">'LAT'</span>, <span class="st">'LON'</span>, <span class="st">'LOCATION'</span>, <span class="st">'Cross Street'</span>, </span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'Weapon Desc'</span>, <span class="st">'Premis Desc'</span>]</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.drop(columns_to_drop, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="co"># we mean normalize the numerical columns, time and age</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'TIME OCC'</span>] <span class="op">=</span> scaler.fit_transform(data[[<span class="st">'TIME OCC'</span>]])</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'Vict Age'</span>] <span class="op">=</span> scaler.fit_transform(data[[<span class="st">'Vict Age'</span>]])</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="co"># use get dummies to make all of our fancy one hot columns with nice names</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.get_dummies(data, columns <span class="op">=</span> [<span class="st">'AREA NAME'</span>, <span class="st">'Crm Cd Desc'</span>, <span class="st">'Vict Descent'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="clean-data" class="level3">
<h3 class="anchored" data-anchor-id="clean-data">Clean Data</h3>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># setting our y variable</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">'Vict Sex'</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># setting our x data (and removing our non-numeric columns)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data.drop([<span class="st">'DATE OCC'</span>, <span class="st">'Vict Sex'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># setting up our training and testing splits</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(x, y, test_size <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>) </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># adding a column of ones to act as intercept for the logistic regression </span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>data[<span class="st">'ones'</span>] <span class="op">=</span> np.ones(x.shape[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluate-sparsity" class="level3">
<h3 class="anchored" data-anchor-id="evaluate-sparsity">Evaluate Sparsity</h3>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># count how many zeroes are in the matrix</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>num_zeros <span class="op">=</span> np.count_nonzero(x <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># figure out the size of the matrix</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>total_elements <span class="op">=</span> x.size</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># find the sparsity ratio</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>sparsity <span class="op">=</span> num_zeros <span class="op">/</span> total_elements</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># sparsity</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sparsity:"</span>, sparsity)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sparsity: 0.9705217893055882</code></pre>
</div>
</div>
</section>
</section>
<section id="simulated-analysis" class="level1">
<h1>Simulated Analysis</h1>
<section id="logistic-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-1">Logistic Regression</h2>
<p>When performing our simulated data analysis, we get some very interesting results. When working with a simulated sample size of 100, the scikit-learn logistic regression achieves an accuracy of 0.65, F1 score of 0.72, and a runtime of only 0.018. At a sample size of 10,000, these numbers change to an accuracy of 0.48, F1 score of 0.51, and a runtime of 0.25. At this scale, our runtime is still very fast. It is interesting, however, that the accuracy is higher in the smaller sample size than the larger sample size. The simulated datasets are both balanced, so it is unclear why these numbers are changing so significantly. Lets compare scikit to our handmade SVD method, however. At a sample size of 100, we obtain an accuracy of 0.91, F1 score of 0.92, and a runtime of 0.04. This is very slightly slower than scikit, but it is significantly more accurate and better balanced between precision and recall. At a sample size of 10,000, we observe an accuracy of 0.50, F1 score of 0.67, and a runtime of 0.45. Again, the SVD is slightly slower than scikit, but we are rewarded with a higher accuracy and F1 score. It seems like, at least at smaller sample sizes, the SVD calculation is much more useful for our purposes. Let’s see what we find in our real data analysis.</p>
<section id="generating-simulation-data" class="level3">
<h3 class="anchored" data-anchor-id="generating-simulation-data">Generating Simulation Data</h3>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated Datasets</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate random values for each column</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_dataframe(n_samples):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> {</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'TIME_OCC'</span>: np.<span class="bu">round</span>(np.random.rand(n_samples), <span class="dv">6</span>),</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Vict Age'</span>: np.<span class="bu">round</span>(np.random.rand(n_samples), <span class="dv">6</span>),</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Vict Sex'</span>: np.random.randint(<span class="dv">2</span>, size<span class="op">=</span>n_samples),</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the numbers of each variable</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    n_areas <span class="op">=</span> <span class="dv">21</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    n_crm_cd_descs <span class="op">=</span> <span class="dv">135</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    n_vict_descs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    n_premis_descs <span class="op">=</span> <span class="dv">304</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    n_weapon_descs <span class="op">=</span> <span class="dv">78</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate lists for one-hot-encoded columns</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    area_names <span class="op">=</span> [<span class="ss">f'Area Name_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_areas)]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    crm_cd_descs <span class="op">=</span> [<span class="ss">f'Crm Cd Desc_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_crm_cd_descs)]</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    vict_descs <span class="op">=</span> [<span class="ss">f'Vict Descent_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_vict_descs)]</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    premis_descs <span class="op">=</span> [<span class="ss">f'Premis Desc_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_premis_descs)]</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    weapon_descs <span class="op">=</span> [<span class="ss">f'Weapon Desc_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_weapon_descs)]</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Put the random values into the empty one-hot-encoded columns</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col_names, num_categories <span class="kw">in</span> <span class="bu">zip</span>([area_names, crm_cd_descs, vict_descs, </span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>                                          premis_descs, weapon_descs],</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>                                         [n_areas, n_crm_cd_descs, n_vict_descs, </span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>                                          n_premis_descs, n_weapon_descs]):</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>        one_hot_encoded <span class="op">=</span> np.zeros((n_samples, num_categories))</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>        random_indices <span class="op">=</span> np.random.randint(num_categories, size<span class="op">=</span>n_samples)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>        one_hot_encoded[np.arange(n_samples), random_indices] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, col_name <span class="kw">in</span> <span class="bu">enumerate</span>(col_names):</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>            df[col_name] <span class="op">=</span> one_hot_encoded[:, i]</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform real-number values into integers</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    df.iloc[:, <span class="dv">3</span>:<span class="dv">562</span>] <span class="op">=</span> df.iloc[:, <span class="dv">3</span>:<span class="dv">562</span>].astype(<span class="bu">int</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="co"># n_samples = 100</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>df_100 <span class="op">=</span> generate_dataframe(<span class="dv">100</span>)</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>sim_data_100 <span class="op">=</span> pd.DataFrame(df_100)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a><span class="co"># n_samples = 10000</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">456</span>)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>df_10000 <span class="op">=</span> generate_dataframe(<span class="dv">10000</span>)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>sim_data_10000 <span class="op">=</span> pd.DataFrame(df_10000)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-10000-row-simulated-dataset" class="level3">
<h3 class="anchored" data-anchor-id="create-10000-row-simulated-dataset">Create 10,000 Row Simulated Dataset</h3>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># setting up our simulated data for 10,000 values</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>y3 <span class="op">=</span> sim_data_10000[<span class="st">'Vict Sex'</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>x3 <span class="op">=</span> sim_data_10000.drop([<span class="st">'Vict Sex'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="logistic-regression-with-10000-rows" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-with-10000-rows">Logistic Regression With 10,000 rows</h3>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># performing the same linear regression from earlier with our simulated data</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(x3, y3, test_size <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>) </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>x3[<span class="st">'ones'</span>] <span class="op">=</span> np.ones(x3.shape[<span class="dv">0</span>])</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>log_regress <span class="op">=</span> LogisticRegression(max_iter <span class="op">=</span> <span class="dv">1000</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>log_regress.fit(x_train, y_train)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_regress.predict(x_test)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>cnf_matrix <span class="op">=</span> metrics.confusion_matrix(y_test, y_pred)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>,metrics.accuracy_score(y_test, y_pred))</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>elapsed <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'run time'</span>, elapsed)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f1_score(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[444 535]
 [488 533]]
Accuracy: 0.4885
run time 0.24000835418701172
0.5102920057443753</code></pre>
</div>
</div>
</section>
<section id="using-svd" class="level3">
<h3 class="anchored" data-anchor-id="using-svd">Using SVD</h3>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># same svd as earlier but with simulated data</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>U, S, Vt <span class="op">=</span> svd(x3, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the pseudo-inverse of S</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>S_inv <span class="op">=</span> np.diag(<span class="dv">1</span> <span class="op">/</span> S)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the parameter estimates using the SVD decomposition</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> Vt.T <span class="op">@</span> S_inv <span class="op">@</span> U.T <span class="op">@</span> y3</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on new data</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> x3 <span class="op">@</span> theta</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply sigmoid function to obtain probabilities</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>y_pred_prob <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>y_pred))</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>elapsed_svd <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'run time'</span>, elapsed_svd)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.where(y_pred_prob <span class="op">&gt;=</span> threshold, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y3, y_pred)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score (y3, y_pred)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'accuracy'</span>, accuracy)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'f1'</span>, f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>run time 1.3358848094940186
accuracy 0.5071
f1 0.6729480459159977</code></pre>
</div>
</div>
</section>
<section id="create-100-row-simulated-dataset" class="level3">
<h3 class="anchored" data-anchor-id="create-100-row-simulated-dataset">Create 100 Row Simulated Dataset</h3>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># setting up simulated data with 100 rows</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y4 <span class="op">=</span> sim_data_100[<span class="st">'Vict Sex'</span>]</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>x4 <span class="op">=</span> sim_data_100.drop([<span class="st">'Vict Sex'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="logistic-regression-with-100-rows" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-with-100-rows">Logistic Regression With 100 rows</h3>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># doing the exact same linear regression</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(x4, y4, test_size <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>) </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>x4[<span class="st">'ones'</span>] <span class="op">=</span> np.ones(x4.shape[<span class="dv">0</span>])</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>log_regress <span class="op">=</span> LogisticRegression(max_iter <span class="op">=</span> <span class="dv">1000</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>log_regress.fit(x_train, y_train)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_regress.predict(x_test)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>cnf_matrix <span class="op">=</span> metrics.confusion_matrix(y_test, y_pred)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>,metrics.accuracy_score(y_test, y_pred))</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>elapsed <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'run time'</span>, elapsed)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'f1'</span>, f1_score(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[4 7]
 [0 9]]
Accuracy: 0.65
run time 0.021770238876342773
f1 0.72</code></pre>
</div>
</div>
</section>
<section id="using-svd-1" class="level3">
<h3 class="anchored" data-anchor-id="using-svd-1">Using SVD</h3>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># doing the exact same svd</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>U, S, Vt <span class="op">=</span> svd(x4, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the pseudo-inverse of S</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>S_inv <span class="op">=</span> np.diag(<span class="dv">1</span> <span class="op">/</span> S)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the parameter estimates using the SVD decomposition</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> Vt.T <span class="op">@</span> S_inv <span class="op">@</span> U.T <span class="op">@</span> y4</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on new data</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> x4 <span class="op">@</span> theta</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply sigmoid function to obtain probabilities</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>y_pred_prob <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>y_pred))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>elapsed_svd <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'run time'</span>, elapsed_svd)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.where(y_pred_prob <span class="op">&gt;=</span> threshold, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y4, y_pred)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score (y4, y_pred)</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'accuracy'</span>, accuracy)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'f1'</span>, f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>run time 0.011603832244873047
accuracy 0.92
f1 0.9285714285714286</code></pre>
</div>
</div>
</section>
<section id="qr-decomposition-was-unable-to-handle-the-size-of-the-data" class="level3">
<h3 class="anchored" data-anchor-id="qr-decomposition-was-unable-to-handle-the-size-of-the-data">QR decomposition was unable to handle the size of the data</h3>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># QR decomposition was also unable to handle the data</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#P, L, U = lu(x)</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#theta = np.linalg.solve(U, np.linalg.solve(L, P @ y))</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">#y_pred = np.dot(x, theta)</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">#y_pred_prob = 1 / (1 + np.exp(-y_pred))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="svm-1" class="level2">
<h2 class="anchored" data-anchor-id="svm-1">SVM</h2>
<p>During the initial implementation of SVM, we used the Quadratic Programming calculation method, which is commonly used for general datasets. However, we encountered difficulties when applying this approach to our real dataset without using the simulated dataset. The main issue was the time complexity of the model. Since the training time of SVM scales quadratically with the number of training samples, the algorithm needs to compute the distance of each sample to all other samples. As a result, the time complexity becomes O(n^2), where n represents the number of training samples. Given that our dataset consists of over 500,000 observations, this resulted in significant computational challenges and the model did not perform effectively. Additionally, PCA was used to reduce the dimension of the data but we still experienced the same memory error as the previous algorithm. Sparse PCA was used to reduce the dimension of data since there are many 0 values in our dataset, but it didn’t work either due to the dimension of the data. We also applied Incremental PCA (IPCA) to analyze the data in smaller batches which, we expected, could help to reduce the dimension of data. In addition to their time inefficiency of the models mentioned, we also encountered memory issues that prevented the model from functioning properly. Therefore, we explored SVM with Gradient Descent as our alternative approach and confirmed that the model worked for both Simulated and Real datasets. In the simulated data with n=100, the model exhibited a running time of 2.51 seconds, but the mean accuracy rate was only 25%, indicating its suboptimal performance. However, as the number of observations increased to n=10,000, the running time extended to approximately 10 minutes. On the positive side, the mean accuracy rate improved to 0.51. This suggests that the model demonstrates better performance in terms of accuracy rate as the dataset size increases.</p>
<section id="generate-simulation-data" class="level3">
<h3 class="anchored" data-anchor-id="generate-simulation-data">Generate Simulation Data</h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated Datasets</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate random values for each column</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_dataframe(n_samples):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> {</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'TIME_OCC'</span>: np.<span class="bu">round</span>(np.random.rand(n_samples), <span class="dv">6</span>),</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Vict Age'</span>: np.<span class="bu">round</span>(np.random.rand(n_samples), <span class="dv">6</span>),</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Vict Sex'</span>: np.random.randint(<span class="dv">2</span>, size<span class="op">=</span>n_samples),</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the numbers of each variable</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    n_areas <span class="op">=</span> <span class="dv">21</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    n_crm_cd_descs <span class="op">=</span> <span class="dv">135</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    n_vict_descs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    n_premis_descs <span class="op">=</span> <span class="dv">304</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    n_weapon_descs <span class="op">=</span> <span class="dv">78</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate lists for one-hot-encoded columns</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    area_names <span class="op">=</span> [<span class="ss">f'Area Name_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_areas)]</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    crm_cd_descs <span class="op">=</span> [<span class="ss">f'Crm Cd Desc_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_crm_cd_descs)]</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    vict_descs <span class="op">=</span> [<span class="ss">f'Vict Descent_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_vict_descs)]</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    premis_descs <span class="op">=</span> [<span class="ss">f'Premis Desc_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_premis_descs)]</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    weapon_descs <span class="op">=</span> [<span class="ss">f'Weapon Desc_</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_weapon_descs)]</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Put the random values into the empty one-hot-encoded columns</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col_names, num_categories <span class="kw">in</span> <span class="bu">zip</span>([area_names, crm_cd_descs, vict_descs, </span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>                                          premis_descs, weapon_descs],</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>                                         [n_areas, n_crm_cd_descs, n_vict_descs, </span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>                                          n_premis_descs, n_weapon_descs]):</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        one_hot_encoded <span class="op">=</span> np.zeros((n_samples, num_categories))</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        random_indices <span class="op">=</span> np.random.randint(num_categories, size<span class="op">=</span>n_samples)</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        one_hot_encoded[np.arange(n_samples), random_indices] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, col_name <span class="kw">in</span> <span class="bu">enumerate</span>(col_names):</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>            df[col_name] <span class="op">=</span> one_hot_encoded[:, i]</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform real-number values into integers</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    df.iloc[:, <span class="dv">3</span>:<span class="dv">562</span>] <span class="op">=</span> df.iloc[:, <span class="dv">3</span>:<span class="dv">562</span>].astype(<span class="bu">int</span>)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a><span class="co"># n_samples = 100</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>df_100 <span class="op">=</span> generate_dataframe(<span class="dv">100</span>)</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>sim_data_100 <span class="op">=</span> pd.DataFrame(df_100)</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a><span class="co"># n_samples = 10000</span></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random seed</span></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">456</span>)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>df_10000 <span class="op">=</span> generate_dataframe(<span class="dv">10000</span>)</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>sim_data_10000 <span class="op">=</span> pd.DataFrame(df_10000)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the simulated data for Testing: n = 100</span></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>X_sim_100 <span class="op">=</span> sim_data_100.drop(<span class="st">"Vict Sex"</span>, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>y_sim_100 <span class="op">=</span> sim_data_100[[<span class="st">"Vict Sex"</span>]]</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>X_s_100_train, X_s_100_test, y_s_100_train, y_s_100_test <span class="op">=</span> train_test_split(X_sim_100, </span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>                                                                            y_sim_100, </span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>                                                                            test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>                                                                            random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the data to numpy arrays</span></span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>X_s_100_train <span class="op">=</span> np.array(X_s_100_train)</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>X_s_100_test <span class="op">=</span> np.array(X_s_100_test)</span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>y_s_100_train <span class="op">=</span> np.array(y_s_100_train)</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>y_s_100_test <span class="op">=</span> np.array(y_s_100_test)</span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the simulated data for Testing: n = 10000</span></span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>X_sim_10000 <span class="op">=</span> sim_data_10000.drop(<span class="st">"Vict Sex"</span>, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>y_sim_10000 <span class="op">=</span> sim_data_10000[[<span class="st">"Vict Sex"</span>]]</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>X_s_10000_train, X_s_10000_test, y_s_10000_train, y_s_10000_test <span class="op">=</span> train_test_split(X_sim_10000, </span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>                                                                                    y_sim_10000, </span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a>                                                                                    test_size<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>                                                                                    random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the data to numpy arrays</span></span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>X_s_10000_train <span class="op">=</span> np.array(X_s_10000_train)</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a>X_s_10000_test <span class="op">=</span> np.array(X_s_10000_test)</span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>y_s_10000_train <span class="op">=</span> np.array(y_s_10000_train)</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a>y_s_10000_test <span class="op">=</span> np.array(y_s_10000_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="svm-with-10000-rows" class="level3">
<h3 class="anchored" data-anchor-id="svm-with-10000-rows">SVM with 10,000 rows</h3>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Test using Simulated Data: n = 10000</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> []</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SVM:</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, learning_rate<span class="op">=</span><span class="fl">0.001</span>, lambda_param<span class="op">=</span><span class="fl">0.01</span>, n_iters<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> learning_rate</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lambda_param <span class="op">=</span> lambda_param</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_iters <span class="op">=</span> n_iters</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        n_samples, n_features <span class="op">=</span> X.shape</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>        y_ <span class="op">=</span> np.where(y <span class="op">&lt;=</span> <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_iters):</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> idx, x_i <span class="kw">in</span> <span class="bu">enumerate</span>(X):</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>                condition <span class="op">=</span> y_[idx] <span class="op">*</span> (np.dot(x_i, <span class="va">self</span>.w) <span class="op">-</span> <span class="va">self</span>.b) <span class="op">&gt;=</span> <span class="dv">1</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> condition:</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.lambda_param <span class="op">*</span> <span class="va">self</span>.w)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> (</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>                        <span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.lambda_param <span class="op">*</span> <span class="va">self</span>.w <span class="op">-</span> np.dot(x_i, y_[idx])</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.b <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> y_[idx]</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>        approx <span class="op">=</span> np.dot(X, <span class="va">self</span>.w) <span class="op">-</span> <span class="va">self</span>.b</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.sign(approx)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> accuracy(<span class="va">self</span>, X, y):</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> <span class="va">self</span>.predict(X)</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> accuracy_score(y, predictions)</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>mod <span class="op">=</span> SVM()</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>mod.fit(X_s_10000_train, y_s_10000_train.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>y_s_10000_pred <span class="op">=</span> mod.predict(X_s_10000_test)</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> mod.accuracy(X_s_10000_test, y_s_10000_test)</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Running Time</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>end_time<span class="op">-</span>start_time <span class="co"># 10 mins</span></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean Accuracy Rate</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>np.mean(accuracy).<span class="bu">round</span>(<span class="dv">2</span>) <span class="co"># 0.51</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>0.51</code></pre>
</div>
</div>
</section>
<section id="svm-with-100-rows" class="level3">
<h3 class="anchored" data-anchor-id="svm-with-100-rows">SVM With 100 rows</h3>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM with Gradient Descent</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Reference: </span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># https://github.com/patrickloeber/MLfromscratch/blob/master/mlfromscratch/svm.py</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated Study</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Test using Simulated Data: n = 100</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> []</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SVM:</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, learning_rate<span class="op">=</span><span class="fl">0.001</span>, lambda_param<span class="op">=</span><span class="fl">0.01</span>, n_iters<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> learning_rate</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lambda_param <span class="op">=</span> lambda_param</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_iters <span class="op">=</span> n_iters</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        n_samples, n_features <span class="op">=</span> X.shape</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        y_ <span class="op">=</span> np.where(y <span class="op">&lt;=</span> <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_iters):</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> idx, x_i <span class="kw">in</span> <span class="bu">enumerate</span>(X):</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>                condition <span class="op">=</span> y_[idx] <span class="op">*</span> (np.dot(x_i, <span class="va">self</span>.w) <span class="op">-</span> <span class="va">self</span>.b) <span class="op">&gt;=</span> <span class="dv">1</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> condition:</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.lambda_param <span class="op">*</span> <span class="va">self</span>.w)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> (</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>                        <span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.lambda_param <span class="op">*</span> <span class="va">self</span>.w <span class="op">-</span> np.dot(x_i, y_[idx])</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.b <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> y_[idx]</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        approx <span class="op">=</span> np.dot(X, <span class="va">self</span>.w) <span class="op">-</span> <span class="va">self</span>.b</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.sign(approx)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> accuracy(<span class="va">self</span>, X, y):</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> <span class="va">self</span>.predict(X)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> accuracy_score(y, predictions)</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>mod <span class="op">=</span> SVM()</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>mod.fit(X_s_100_train, y_s_100_train.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>y_s_100_pred <span class="op">=</span> mod.predict(X_s_100_test)</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> mod.accuracy(X_s_100_test, y_s_100_test)</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Running time</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">-</span> start_time <span class="co"># 2.51 sec</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean Accuracy Rate</span></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>np.mean(accuracy).<span class="bu">round</span>(<span class="dv">2</span>) <span class="co"># 0.25</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>0.25</code></pre>
</div>
</div>
</section>
</section>
<section id="mlp-binary-classifier-1" class="level2">
<h2 class="anchored" data-anchor-id="mlp-binary-classifier-1">MLP Binary Classifier</h2>
<p>For the MLP Binary Classifier we are able to achieve an F1 score of about 0.62 for both simulated datasets with 10,000 rows and 100 rows. The major difference is in training time which takes over a minute for the dataset with 10,000 rows and under 5 seconds for the dataset with 100 rows.</p>
<section id="mlp-binary-classifier-code" class="level3">
<h3 class="anchored" data-anchor-id="mlp-binary-classifier-code">MLP Binary Classifier Code</h3>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLPClassifier:</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> []</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> []</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activations <span class="op">=</span> []</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z <span class="op">=</span> []</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.error <span class="op">=</span> []</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gradient <span class="op">=</span> [] </span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_shape <span class="op">=</span> (<span class="dv">0</span>,<span class="dv">0</span>) </span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _sigmoid(<span class="va">self</span>,z):</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _sigmoid_prime(<span class="va">self</span>,z):</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>        sigmoid_z <span class="op">=</span> <span class="va">self</span>._sigmoid(z)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_z <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> sigmoid_z)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> cross_entropy_prime(<span class="va">self</span>,y_true, y_pred):</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>        epsilon <span class="op">=</span> <span class="fl">1e-7</span>  <span class="co"># Small value to avoid division by zero</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>        clipped_y_pred <span class="op">=</span> np.clip(y_pred, epsilon, <span class="fl">1.0</span> <span class="op">-</span> epsilon)  <span class="co"># Clip predicted values to avoid numerical instability</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>(y_true <span class="op">/</span> clipped_y_pred <span class="op">-</span> (<span class="dv">1</span> <span class="op">-</span> y_true) <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> clipped_y_pred))</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_input_layer(<span class="va">self</span>,num_nodes):</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_nodes <span class="op">=</span> num_nodes</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_hidden_layer(<span class="va">self</span>,num_nodes):</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activations.append(np.empty((num_nodes,<span class="dv">1</span>,)))</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z.append(np.empty(num_nodes))</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias.append(np.random.randn(num_nodes,<span class="dv">1</span>,) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.activations) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights.append(np.random.randn(<span class="va">self</span>.activations[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>],</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>                                                <span class="va">self</span>.X_nodes ) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.weights.append(np.random.randn(<span class="va">self</span>.activations[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>],</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>                                                <span class="va">self</span>.activations[<span class="op">-</span><span class="dv">2</span>].shape[<span class="dv">0</span>]) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_output_layer(<span class="va">self</span>,num_nodes):</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activations.append(np.empty((num_nodes,<span class="dv">1</span>)))</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.z.append(np.empty(num_nodes))</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias.append(np.random.randn(num_nodes,<span class="dv">1</span>) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights.append(np.random.randn(<span class="va">self</span>.activations[<span class="op">-</span><span class="dv">1</span>].shape[<span class="dv">0</span>],</span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>                                            <span class="va">self</span>.activations[<span class="op">-</span><span class="dv">2</span>].shape[<span class="dv">0</span>]) <span class="op">*</span> <span class="fl">0.01</span>)</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>           </span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _feed_forward(<span class="va">self</span>,X):</span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>        X <span class="op">=</span> X.reshape(X.shape[<span class="dv">0</span>],<span class="dv">1</span>)</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.activations)):</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> l <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> (<span class="va">self</span>.weights[l] <span class="op">@</span> X) <span class="op">+</span> <span class="va">self</span>.bias[l]</span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> (<span class="va">self</span>.weights[l] <span class="op">@</span> <span class="va">self</span>.activations[l <span class="op">-</span> <span class="dv">1</span>]) <span class="op">+</span> <span class="va">self</span>.bias[l]</span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.z[l] <span class="op">=</span> z </span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.activations[l] <span class="op">=</span> <span class="va">self</span>._sigmoid(z)</span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _back_prop(<span class="va">self</span>,y_true):</span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a>        output_error <span class="op">=</span> <span class="va">self</span>.cross_entropy_prime(y_true, </span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a>                                                <span class="va">self</span>.activations[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>                                                ) <span class="op">*</span> <span class="va">self</span>._sigmoid_prime(<span class="va">self</span>.z[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.error[<span class="op">-</span><span class="dv">1</span>] <span class="op">+=</span> output_error</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.activations) <span class="op">-</span> <span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>            delta <span class="op">=</span> (<span class="va">self</span>.weights[l <span class="op">+</span> <span class="dv">1</span>].T <span class="op">@</span> <span class="va">self</span>.error[l <span class="op">+</span> <span class="dv">1</span>]) <span class="op">*</span> <span class="va">self</span>._sigmoid_prime(<span class="va">self</span>.z[l])</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a><span class="co"># so you can see :)</span></span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a><span class="co">#delta = (self.weights[l + 1].T @ self.error[l + 1]) * self._sigmoid_prime(self.z[l])</span></span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.error[l] <span class="op">+=</span> delta</span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>.weights)<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.gradient[l] <span class="op">+=</span> <span class="va">self</span>.error[l] <span class="op">@</span> <span class="va">self</span>.activations[l <span class="op">-</span> <span class="dv">1</span>].T</span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>,X,y,learning_rate,m,num_epochs):</span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.time()</span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.error <span class="op">=</span> [np.zeros_like(arr) <span class="cf">for</span> arr <span class="kw">in</span> <span class="va">self</span>.bias]</span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gradient <span class="op">=</span> [np.zeros_like(arr) <span class="cf">for</span> arr <span class="kw">in</span> <span class="va">self</span>.weights]</span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Copy the array to preserve the original</span></span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a>            remaining_rows <span class="op">=</span> X.copy()</span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Continue sampling until there are no rows left</span></span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> remaining_rows.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Randomly sample rows without replacement</span></span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a>                sample_size <span class="op">=</span> <span class="bu">min</span>(m, remaining_rows.shape[<span class="dv">0</span>])  <span class="co"># Set the desired sample size (e.g., 2)</span></span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a>                mini_batch <span class="op">=</span> np.random.choice(remaining_rows.shape[<span class="dv">0</span>], </span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a>                                              size<span class="op">=</span>sample_size, </span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a>                                              replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb29-96"><a href="#cb29-96" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb29-97"><a href="#cb29-97" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> row <span class="kw">in</span> mini_batch: </span>
<span id="cb29-98"><a href="#cb29-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-99"><a href="#cb29-99" aria-hidden="true" tabindex="-1"></a>                    <span class="co">#self._feed_forward(np.expand_dims(X[row],axis = 1))</span></span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>._feed_forward(X[row])</span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>._back_prop(y[row])</span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a>               </span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Remove the sampled rows from the remaining rows</span></span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a>                remaining_rows <span class="op">=</span> np.delete(remaining_rows, mini_batch, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.weights <span class="op">=</span> [weights <span class="op">-</span> ((learning_rate <span class="op">/</span> <span class="bu">len</span>(mini_batch)) <span class="op">*</span> gradient ) <span class="cf">for</span> weights, gradient <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.weights, <span class="va">self</span>.gradient)]</span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.bias <span class="op">=</span> [bias <span class="op">-</span> ((learning_rate <span class="op">/</span> <span class="bu">len</span>(mini_batch)) <span class="op">*</span> error)  <span class="cf">for</span> bias, error <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.bias, <span class="va">self</span>.error)]</span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a><span class="co"># so you can see :)</span></span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a><span class="co">#self.weights = [weights - ((learning_rate / len(mini_batch)) * gradient ) for weights, gradient in zip(self.weights, self.gradient)]</span></span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a><span class="co">#self.bias = [bias - ((learning_rate / len(mini_batch)) * error)  for bias, error in zip(self.bias, self.error)]</span></span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-113"><a href="#cb29-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-114"><a href="#cb29-114" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a>        total_time <span class="op">=</span> time.time() <span class="op">-</span> start_time </span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Elapsed time:"</span>, total_time, <span class="st">"seconds"</span>)</span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-118"><a href="#cb29-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-119"><a href="#cb29-119" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>,X_test):</span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> []</span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> row <span class="kw">in</span> <span class="bu">range</span>(X_test.shape[<span class="dv">0</span>]):</span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._feed_forward(X_test[row])</span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.activations[<span class="op">-</span><span class="dv">1</span>][<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.5</span>:</span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a>                predictions.append(<span class="dv">1</span>)</span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a>                predictions.append(<span class="dv">0</span>)</span>
<span id="cb29-127"><a href="#cb29-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> predictions </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="mlp-training-with-10000-rows" class="level3">
<h3 class="anchored" data-anchor-id="mlp-training-with-10000-rows">MLP Training With 10,000 rows</h3>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(x3, </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>                                                    y3, </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>) </span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.values</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.values</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> y_train.values</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> y_test.values</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MLPClassifier()</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>clf.add_input_layer(<span class="dv">561</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>clf.add_hidden_layer(<span class="dv">5</span>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>clf.add_hidden_layer(<span class="dv">5</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>clf.add_output_layer(<span class="dv">1</span>)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>clf.train(X_train,y_train,<span class="fl">0.01</span>,<span class="dv">50</span>,<span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Elapsed time: 238.92144536972046 seconds</code></pre>
</div>
</div>
</section>
<section id="mlp-prediction-with-10000-rows" class="level3">
<h3 class="anchored" data-anchor-id="mlp-prediction-with-10000-rows">MLP Prediction With 10,000 rows</h3>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score: "</span>,<span class="bu">round</span>(f1_score(y_test,y_pred),<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F1 Score:  0.68</code></pre>
</div>
</div>
</section>
<section id="mlp-training-with-100-rows" class="level3">
<h3 class="anchored" data-anchor-id="mlp-training-with-100-rows">MLP Training With 100 rows</h3>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(x4,</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>                                                    y4, </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>) </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.values</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.values</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> y_train.values</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> y_test.values</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> MLPClassifier()</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>clf.add_input_layer(<span class="dv">561</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>clf.add_hidden_layer(<span class="dv">5</span>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>clf.add_hidden_layer(<span class="dv">5</span>)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>clf.add_output_layer(<span class="dv">1</span>)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>clf.train(X_train,y_train,<span class="fl">0.01</span>,<span class="dv">5</span>,<span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Elapsed time: 1.7451488971710205 seconds</code></pre>
</div>
</div>
</section>
<section id="mlp-prediction-with-100-rows" class="level3">
<h3 class="anchored" data-anchor-id="mlp-prediction-with-100-rows">MLP Prediction With 100 rows</h3>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score: "</span>,<span class="bu">round</span>(f1_score(y_test,y_pred),<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F1 Score:  0.62</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="real-data-analysis" class="level1">
<h1>Real Data Analysis</h1>
<section id="logistic-regression-2" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-2">Logistic Regression</h2>
<p>In calculating the logistic regression model of our dataset, the scikit-learn function was a bit lacking. It worked decently well, with an accuracy of 0.63, an F1 score of 0.61 and a runtime of about a minute. This runtime could be improved, however. In order to improve on the runtime, I decided to use the SVD method of linear regression. This method would be ideal for the dataset, being that it is very large, and very sparse (97%, as stated above). When we apply the SVD, we get some very interesting results, very quickly. We see an immediate and immense improvement in the runtime. The SVD takes only 7.15 seconds to finish operation. That’s 88% faster than the scikit-learn’s logistic regression function! This is a huge improvement already. Let’s take a look at our new accuracy and F1 scores, however. With the SVD, we observed an accuracy of 0.50, and an F1 score of 0.66. This lower accuracy but higher F1 score leads us to believe that this method has struck a slightly better balance between precision and recall. It is worth noting that the LU and QR methods were attempted, but due to the nature of their calculations, were unable to be performed with a dataset this large. Due to the necessity of needing to store the entire matrix (which with this data is 530,626x530,626), there was simply nowhere near enough memory to store this gargantuan matrix. Since the SVD is able to exploit the extremely high level of sparsity in this matrix, it was able to perform its required calculations no problem. Further optimizations would be needed in memory allocation to attempt the other decomposition methods. There isn’t much that can be done further in the way of data cleaning, perhaps selecting a smaller sample of the data. This could have the consequence of harming the accuracy of our model, however, which due to the nature of the data, would not be ideal. It would likely be less expensive to purchase more memory, than it would be to incorrectly allocate city-wide resources to the wrong area. It seems that our conclusions from the simulated data analysis are continued here. The SVD, while a little bit less accurate, is much better at scaling to the full-size dataset, that scikit is simply unable to match. This level of time savings would result in massive real world savings in both computational and opportunity costs when related to performing these computations.</p>
<section id="logistic-regression-with-real-data" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression-with-real-data">Logistic Regression With Real Data</h3>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set start time</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># set logistic regression function and give it a bunch of iterations to work with</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>log_regress <span class="op">=</span> LogisticRegression(max_iter <span class="op">=</span> <span class="dv">1000</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co"># train it with our training sets</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>log_regress.fit(x_train, y_train)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># make our predictions against our testing set</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> log_regress.predict(x_test)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co"># doing the end time</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co"># setting up confusion matrix</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>cnf_matrix <span class="op">=</span> metrics.confusion_matrix(y_test, y_pred)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="co"># calculating all relevant statistics</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnf_matrix)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>,metrics.accuracy_score(y_test, y_pred))</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>elapsed <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'run time'</span>, elapsed)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'f1 score'</span>, f1_score(y_test, y_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[4 7]
 [0 9]]
Accuracy: 0.65
run time 0.02385735511779785
f1 score 0.72</code></pre>
</div>
</div>
</section>
<section id="using-svd-with-real-data" class="level3">
<h3 class="anchored" data-anchor-id="using-svd-with-real-data">Using SVD With Real Data</h3>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># setting our x and y sets from wayyyyyy earlier as numpy arrays</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># we won't be doing a training/testing set here since we don't need that for this method</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to_numpy()</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to_numpy()</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co"># doing start time</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># setting up our important parts of the SVD package</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>U, S, Vt <span class="op">=</span> svd(x, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co"># finding the pseudoinverse of S for calulcation</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>S_inv <span class="op">=</span> np.diag(<span class="dv">1</span> <span class="op">/</span> S)</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co"># getting our parameter estimates with the SVD decompositions</span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> Vt.T <span class="op">@</span> S_inv <span class="op">@</span> U.T <span class="op">@</span> y</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="co"># making predictions</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> x <span class="op">@</span> theta</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co"># obtaining probabilities</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>y_pred_prob <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>y_pred))</span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>end <span class="op">=</span> time.time()</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>elapsed_svd <span class="op">=</span> end <span class="op">-</span> start</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'run time'</span>, elapsed_svd)</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a><span class="co"># setting up our predictions functions</span></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.where(y_pred_prob <span class="op">&gt;=</span> threshold, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a><span class="co"># calculating our accuracy and f1 score here against our actual data </span></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a><span class="co"># and the predictions we made</span></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y, y_pred)</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score (y, y_pred)</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'accuracy'</span>, accuracy)</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'f1'</span>, f1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>run time 10.492974758148193
accuracy 0.5013757335675222
f1 0.6672502109688723</code></pre>
</div>
</div>
</section>
</section>
<section id="svm-2" class="level2">
<h2 class="anchored" data-anchor-id="svm-2">SVM</h2>
<p>Due to memory issues, the previous models that utilized PCA or quadratic computing did not work at all. Therefore, in the real data analysis, we only attempted to fit the SVM model using gradient descent, which was the only viable option. When applying this model to real data in our study, however, it did work, but exhibited significantly poor efficiency in terms of performance. It is worth noting that our training dataset contained nearly 500,000 observations, which is considerably larger than the simulated dataset in terms of quantity. When fitting the model, the mean accuracy rate was 0.6, slightly better than the previous simulated model in terms of accuracy. However, the running time exceeded 5 hours which is significantly inefficient in real-world analysis settings. Therefore, we concluded that SVM with gradient descent can also encounter difficulties when dealing with datasets that have a high number of dimensions. The curse of dimensionality could have a negative impact on the effectiveness of the algorithm due to the large numbers of features, which can still result in increased computational complexity and a higher likelihood of overfitting. Hence, in situations where the data has significantly high dimensionality, as the multiple one-hot-encoded variables we used in this analysis, it may be better to try alternative methods such as feature selection,multiple uses of dimensionality reduction techniques at the same time, or employing advanced algorithms specifically designed to handle high-dimensional data.</p>
<section id="svm-training-with-real-data" class="level3">
<h3 class="anchored" data-anchor-id="svm-training-with-real-data">SVM Training With Real Data</h3>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Real Data Study</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> []</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SVM:</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, learning_rate<span class="op">=</span><span class="fl">0.001</span>, lambda_param<span class="op">=</span><span class="fl">0.01</span>, n_iters<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> learning_rate</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lambda_param <span class="op">=</span> lambda_param</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_iters <span class="op">=</span> n_iters</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> <span class="va">None</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> <span class="va">None</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>        n_samples, n_features <span class="op">=</span> X.shape</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>        y_ <span class="op">=</span> np.where(y <span class="op">&lt;=</span> <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> np.zeros(n_features)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_iters):</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> idx, x_i <span class="kw">in</span> <span class="bu">enumerate</span>(X):</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>                condition <span class="op">=</span> y_[idx] <span class="op">*</span> (np.dot(x_i, <span class="va">self</span>.w) <span class="op">-</span> <span class="va">self</span>.b) <span class="op">&gt;=</span> <span class="dv">1</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> condition:</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.lambda_param <span class="op">*</span> <span class="va">self</span>.w)</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.w <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> (</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>                        <span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.lambda_param <span class="op">*</span> <span class="va">self</span>.w <span class="op">-</span> np.dot(x_i, y_[idx])</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.b <span class="op">-=</span> <span class="va">self</span>.lr <span class="op">*</span> y_[idx]</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>        approx <span class="op">=</span> np.dot(X, <span class="va">self</span>.w) <span class="op">-</span> <span class="va">self</span>.b</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.sign(approx)</span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> accuracy(<span class="va">self</span>, X, y):</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> <span class="va">self</span>.predict(X)</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> accuracy_score(y, predictions)</span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a><span class="co">#mod = SVM()</span></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a><span class="co">#mod.fit(X_train, y_train.reshape(-1))</span></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a><span class="co">#y__pred = mod.predict(X__test)</span></span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a><span class="co">#accuracy = mod.accuracy(X_test, y_test)</span></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a><span class="co">#nd_time = time.time()</span></span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Running Time</span></span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a><span class="co">#end_time - start_time # Approximately 5 hours</span></span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean Accuracy Rate</span></span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a><span class="co">#np.mean(accuracy).round(2) # 0.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="mlp-binary-classifier-2" class="level2">
<h2 class="anchored" data-anchor-id="mlp-binary-classifier-2">MLP Binary Classifier</h2>
<p>For the MLP Binary Classifier we are able to achieve an F1 score of about 0.62 for the real dataset with a couple hundred rows of data. To account for this change in scale I made the batch size larger and decreased the number of epochs to be able to render this document on my local computer. If we wanted to get the best performance and utilize this model to its full potential we would have to run it on distributed cloud infrastructure.</p>
<section id="mlp-training-with-real-data" class="level3">
<h3 class="anchored" data-anchor-id="mlp-training-with-real-data">MLP Training With Real Data</h3>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See MLPClassifier Class code in simulation study</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> MLPClassifier()</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>test.add_input_layer(<span class="dv">561</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>test.add_hidden_layer(<span class="dv">5</span>)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>test.add_hidden_layer(<span class="dv">5</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>test.add_output_layer(<span class="dv">1</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>test.train(X_train,y_train,<span class="fl">0.01</span>,<span class="dv">1000</span>,<span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Elapsed time: 0.6965768337249756 seconds</code></pre>
</div>
</div>
</section>
<section id="mlp-prediction-with-real-data" class="level3">
<h3 class="anchored" data-anchor-id="mlp-prediction-with-real-data">MLP Prediction With Real Data</h3>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> test.predict(X_test)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score: "</span>,<span class="bu">round</span>(f1_score(y_test,y_pred),<span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F1 Score:  0.62</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this final report we were able to explore three different machine learning methods and apply them to a practical problem for the people of Los Angeles. We were able to predict whether the victim of a specific crime was male or female with a maxium F1 score of 0.92 for our small simulation study and around 0.72 using our real data. We also found that for this problem it makes sense to use logistic regression over the other more sophisticated methods due to its faster computation time. In order to increase our prediction F1 score with this large of data we need to implement these methods on distributed cloud infrastructure to unlock the full potential of our data.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>